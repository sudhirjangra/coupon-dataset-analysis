








import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.impute import SimpleImputer
pd.set_option('display.max_columns', None)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, roc_auc_score, classification_report
from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, roc_auc_score, classification_report
# from ydata_profiling import ProfileReport
# import plotly.graph_objects as go
# from plotly.subplots import make_subplots





df = pd.read_csv('DS_DATA.csv')








df.shape





df.info()





df.sample(5)





print(df.isnull().mean().mul(100).map("{:.2f}%".format))





df.drop(columns='car', inplace=True)





si = SimpleImputer(strategy='most_frequent')
cols = ['Bar','CoffeeHouse','CarryAway','RestaurantLessThan20','Restaurant20To50']
df[cols] = si.fit_transform(df[cols])





df.loc[df.duplicated()]





# we have 291 duplicate values, we are dropping them
df.drop_duplicates(inplace=True)
df.duplicated().sum()





df.describe()





cate_cols = df.columns[df.dtypes=='object'].tolist()
num_cols = df.columns[df.dtypes=='int64'].tolist()
print(f'Categorical Columns: {cate_cols}"\n\n",Numeric Columns: {num_cols}')


df.sample(5)


# Categorical-Columns: ['destination', 'passanger', 'weather', 'coupon', 'expiration', 'gender', 'age', 'maritalStatus', 
# 'education', 'occupation', 'income', 'car', 'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']
fig = px.pie(df, names='destination', title='Destination')
fig.show()
fig = px.histogram(df, x='passanger')
fig.show()
fig = px.pie(df, names='weather', title='Weather')
fig.show()
fig = px.histogram(df, x='coupon')
fig.show()
fig = px.pie(df, names='maritalStatus', title='maritalStatus')
fig.show()





# Numeric Columns: ['temperature', 'has_children', 'toCoupon_GEQ5min', 'toCoupon_GEQ15min', 'toCoupon_GEQ25min', 'direction_same',
# 'direction_opp', 'Accept(Y/N?)']
fig = px.histogram(df, x='temperature', nbins=3)
fig.show()
fig = px.histogram(df, x='has_children', nbins=3)
fig.show()
fig = px.histogram(df, x='toCoupon_GEQ15min', nbins=3)
fig.show()
fig = px.histogram(df, x='toCoupon_GEQ25min', nbins=3)
fig.show()
fig = px.histogram(df, x='direction_same', nbins=3)
fig.show()
fig = px.histogram(df, x='direction_opp', nbins=3)
fig.show()
fig = px.histogram(df, x='Accept(Y/N?)', nbins=3)
fig.show()

# sns.kdeplot(df['temperature'])
# plt.show()


sns.countplot(df, y='occupation', legend=True)
plt.show()


sns.countplot(df, x='age')
plt.show()


sns.countplot(df, x='maritalStatus')
plt.show()


fig = px.histogram(df, x='age')
fig.show()


sns.heatmap(df.corr(numeric_only=True),annot=True)
plt.show()


# sns.pairplot(df)
# plt.show()


cols_list = df.columns.tolist()
cols_list


numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns

for col in numeric_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_limit = Q1 - 1.5 * IQR
    upper_limit = Q3 + 1.5 * IQR
    outlier_count = df[(df[col] < lower_limit) | (df[col] > upper_limit)].shape[0]
    total_count = df.shape[0]
    outlier_percentage = (outlier_count / total_count) * 100
    print(f"{col}: {outlier_percentage:.2f}% outliers")


print(df[['toCoupon_GEQ25min']].value_counts())
print(df[['direction_same']].value_counts())
print(df[['direction_opp']].value_counts())


sns.kdeplot(df['direction_opp'])
sns.kdeplot(df['direction_same'])


def make_direction(row):
    if row['direction_same'] == 1 and row['direction_opp'] == 0:
        return 'same'
    if row['direction_opp'] == 1 and row['direction_same'] == 0:
        return 'opposite'

df['direction'] = df.apply(make_direction, axis=1)
df['direction'] = pd.Categorical(df['direction'],
                                      categories=['same','opposite'],
                                      ordered=False)


sns.barplot(df['direction'])
df.direction.value_counts()


df.drop(columns=['direction_opp','direction_same'], inplace=True)


# removing 'toCoupon_GEQ5min' as it has only one kind of values: '1'
df.drop(columns='toCoupon_GEQ5min', inplace=True)


fig = px.box(df, y='temperature', x='weather', points = "all")
fig.show()


# The dataset shows that Sunny conditions are associated with temperatures between 55-80, while Rainy conditions occur at 55 & snowy at 30


new_age = {
    'below21': '<21',
    '21': '21-30',
    '26': '21-30',
    '31': '31-40',
    '36': '31-40',
    '41': '41-50',
    '46': '41-50',
    '50plus': '50+'
}

age_order = ['<21', '21-30', '31-40', '41-50', '50+']

df['age_group'] = df['age'].map(new_age).astype(str).str.strip()
df.drop(columns='age', inplace=True)

df['age_group_ord'] = pd.Categorical(
    df['age_group'],
    categories=age_order,
    ordered=True
).codes

df['age_group_ord'] = df['age_group_ord'].replace(-1, np.nan).astype('Int64')
df.drop(columns='age_group', inplace=True)


df.income.unique().tolist()


# converting to ordinal categories
income_order = ['Less than $12500', '$12500 - $24999', '$25000 - $37499', '$37500 - $49999', '$50000 - $62499', '$62500 - $74999', '$75000 - $87499','$85000 - $99999','$100000 or More']
if 'income' in df.columns:
    df['income'] = df['income'].astype(str).str.strip()
    df['income_ord'] = pd.Categorical(df['income'], categories = income_order, ordered=True).codes
    df['income_ord'] = df['income_ord'].replace(-1, np.nan).astype('Int64')


df.sample(5)


for i in df.columns:
    print(i, df[i].value_counts().count())


freq_map = {'never':0, 'less1': 1, '<1':1, '1:':1, '1~3':2, '4~8': 3, 'gt8': 4, 'morethan8': 4}
freq_cols= ['Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20','Restaurant20To50']
for i in freq_cols:
    if i in df.columns:
        df[i] = df[i].astype(str).str.strip().str.lower().replace({'<1':'less', 'more than 8':'gt8'})
        df[i] = df[i].map(freq_map).astype('Int64')


numeric_cols = [c for c in ['temperature','has_children','toCoupon_GEQ15min','toCoupon_GEQ25min','income_ord','age_group_ord'] if c in df.columns] + \
               [c for c in freq_cols if c in df.columns]
cat_cols = [c for c in ['destination','passanger','weather','coupon','expiration','gender','maritalStatus','education','occupation','direction'] if c in df.columns]


df_ohe = pd.get_dummies(df[cat_cols], drop_first=True, dtype=np.int64) if cat_cols else pd.DataFrame(index=df.index)


feature_cols = numeric_cols + list(df_ohe.columns)
x = pd.concat([df[numeric_cols].astype(float).fillna(0), df_ohe], axis=1)


y = df['Accept(Y/N?)'].astype(int)


scaler = StandardScaler()
if numeric_cols:
    x[numeric_cols] = scaler.fit_transform(x[numeric_cols])


xtrain, xtest, ytrain, ytest = train_test_split(
    x, y, stratify=y, test_size=0.2, random_state=42
)


lr = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

scores = cross_val_score(lr, x, y, cv=cv, scoring='f1')
print("Cross-validated F1 scores:", scores)
print("Mean F1:", scores.mean())


lr.fit(xtrain, ytrain)
ypred = lr.predict(xtest)
yprob = lr.predict_proba(xtest)[:, 1]


print("Test F1:", f1_score(ytest, ypred))
print("Test AUC:", roc_auc_score(ytest, yprob))
print(classification_report(ytest, ypred))


print(classification_report(ytest, ypred))


from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(
    n_estimators=100,
    min_samples_split=2,
    min_samples_leaf=1,
    max_features='sqrt',
    n_jobs=-1,
    random_state=42, 
)


clf.fit(xtrain, ytrain)
ypred = clf.predict(xtest)


print(classification_report(ytest, ypred))


print("ROC_AUC: \n", roc_auc_score(ytest, ypred))
